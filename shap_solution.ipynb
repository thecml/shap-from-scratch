{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courtesy of https://randomrealizations.com/posts/shap-from-scratch/\n",
    "\n",
    "import numpy as np \n",
    "from typing import Any, Callable, Iterable\n",
    "from math import factorial\n",
    "from itertools import chain, combinations\n",
    "\n",
    "class ShapFromScratchExplainer():\n",
    "    def __init__(self,\n",
    "                 model: Callable[[np.ndarray], float], \n",
    "                 background_dataset: np.ndarray,\n",
    "                 max_samples: int = None):\n",
    "        self.model = model # Set model\n",
    "        if max_samples: # If max samples, randomly sample a subset of the background dataset\n",
    "            max_samples = min(max_samples, background_dataset.shape[0]) \n",
    "            rng = np.random.default_rng()\n",
    "            self.background_dataset = rng.choice(background_dataset, \n",
    "                                                 size=max_samples, \n",
    "                                                 replace=False, axis=0)\n",
    "        else: # Use the full background dataset\n",
    "            self.background_dataset = background_dataset\n",
    "\n",
    "    def shap_values(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute SHAP values for instances in DataFrame or 2D array\"\"\"\n",
    "        shap_values = np.empty(X.shape)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                shap_values[i, j] = self._compute_single_shap_value(j, X[i, :])\n",
    "        return shap_values\n",
    "       \n",
    "    def _compute_single_shap_value(self, \n",
    "                                   feature: int,\n",
    "                                   instance: np.array) -> float:\n",
    "        \"\"\"\n",
    "        Compute a single SHAP value given feature of interest and instance\n",
    "        (equation 4 in SHAP paper)\n",
    "        \"\"\"\n",
    "        n_features = len(instance)\n",
    "        shap_value = 0\n",
    "        for subset in self._get_all_other_feature_subsets(n_features, feature):\n",
    "            n_subset = len(subset)\n",
    "            prediction_without_feature = self._subset_model_approximation(\n",
    "                subset, \n",
    "                instance\n",
    "            )\n",
    "            prediction_with_feature = self._subset_model_approximation(\n",
    "                subset + (feature,), \n",
    "                instance\n",
    "            )\n",
    "            factor = self._permutation_factor(n_features, n_subset)\n",
    "            shap_value += factor * (prediction_with_feature - prediction_without_feature)\n",
    "        return shap_value\n",
    "    \n",
    "    def _get_all_subsets(self, items: list) -> Iterable:\n",
    "        \"\"\"Generate all possible subsets\"\"\"\n",
    "        return chain.from_iterable(combinations(items, r) for r in range(len(items)+1))\n",
    "    \n",
    "    def _get_all_other_feature_subsets(self, n_features, feature_of_interest):\n",
    "        \"\"\"Generate all subsets of features excluding the feature of interest\"\"\"\n",
    "        all_other_features = [j for j in range(n_features) if j != feature_of_interest]\n",
    "        return self._get_all_subsets(all_other_features)\n",
    "\n",
    "    def _permutation_factor(self, n_features, n_subset):\n",
    "        return (\n",
    "            factorial(n_subset) \n",
    "            * factorial(n_features - n_subset - 1) \n",
    "            / factorial(n_features) \n",
    "        )\n",
    "    \n",
    "    def _subset_model_approximation(self, \n",
    "                                    feature_subset: tuple[int, ...], \n",
    "                                    instance: np.array) -> float:\n",
    "        \"\"\" \n",
    "        Approximate subset model prediction  (Equation 11 in SHAP paper)\n",
    "        \\hat{f}_S(x) = E_{x_{\\hat{S}}}[f_S(x)]\n",
    "        for feature subset S on single instance x\n",
    "        \"\"\"\n",
    "        masked_background_dataset = self.background_dataset.copy()\n",
    "        for j in range(masked_background_dataset.shape[1]):\n",
    "            if j in feature_subset:\n",
    "                masked_background_dataset[:, j] = instance[j]\n",
    "        conditional_expectation_of_model = np.mean(\n",
    "            self.model(masked_background_dataset)\n",
    "        )\n",
    "        return conditional_expectation_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "X, y = load_diabetes(as_frame=False, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "\n",
    "lin_model = LinearRegression().fit(X_train, y_train)\n",
    "rfr_model = RandomForestRegressor().fit(X_train, y_train)\n",
    "gbt_model = GradientBoostingRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def compare_methods(model, X_background, X_instances):\n",
    "        \n",
    "    library_explainer = shap.KernelExplainer(model.predict, X_background)\n",
    "    library_shap_values = library_explainer.shap_values(X_instances)\n",
    "\n",
    "    from_scratch_explainer = ShapFromScratchExplainer(model.predict, X_background)\n",
    "    from_scratch_shap_values = from_scratch_explainer.shap_values(X_instances)\n",
    "    \n",
    "    print(library_shap_values)\n",
    "    print()\n",
    "    print(from_scratch_shap_values)\n",
    "\n",
    "    return np.allclose(library_shap_values, from_scratch_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.07328990e+00  1.19742336e+01 -6.78307320e+00 -8.87444563e+00\n",
      "  -1.05142093e+02  5.90556891e+01  3.22045528e+00  6.97888597e+00\n",
      "   1.51290727e+01 -6.34130862e-01]\n",
      " [ 2.45475216e+00  1.19742336e+01  1.67692643e+01  5.83472803e+00\n",
      "   3.01327907e+01 -1.28318456e+01  9.90223092e-01 -1.42787624e+01\n",
      "  -2.10969996e+01 -1.31967774e+00]\n",
      " [ 1.60462154e+00 -1.29720864e+01 -5.60545632e+00 -7.53724802e+00\n",
      "  -8.52852297e+01  2.03348095e+01  7.68091966e+00 -3.64993823e+00\n",
      "   4.94500912e+01 -1.14829102e+00]\n",
      " [ 2.56101848e+00  1.19742336e+01  2.50125824e+01  2.81258121e+01\n",
      "  -4.18483403e+01  1.41458164e+01 -8.37675211e+00  3.78024761e+01\n",
      "   5.87830524e+01  2.10805665e+00]\n",
      " [ 1.16892960e-01 -1.29720864e+01 -1.44375829e+01 -3.52565521e+00\n",
      "  -2.69556925e+01  2.25564993e+01  9.81302164e-02  6.97888597e+00\n",
      "  -9.64263767e+00 -8.05517582e-01]]\n",
      "\n",
      "[[ 1.07328990e+00  1.19742336e+01 -6.78307320e+00 -8.87444563e+00\n",
      "  -1.05142093e+02  5.90556891e+01  3.22045528e+00  6.97888597e+00\n",
      "   1.51290727e+01 -6.34130862e-01]\n",
      " [ 2.45475216e+00  1.19742336e+01  1.67692643e+01  5.83472803e+00\n",
      "   3.01327907e+01 -1.28318456e+01  9.90223092e-01 -1.42787624e+01\n",
      "  -2.10969996e+01 -1.31967774e+00]\n",
      " [ 1.60462154e+00 -1.29720864e+01 -5.60545632e+00 -7.53724802e+00\n",
      "  -8.52852297e+01  2.03348095e+01  7.68091966e+00 -3.64993823e+00\n",
      "   4.94500912e+01 -1.14829102e+00]\n",
      " [ 2.56101848e+00  1.19742336e+01  2.50125824e+01  2.81258121e+01\n",
      "  -4.18483403e+01  1.41458164e+01 -8.37675211e+00  3.78024761e+01\n",
      "   5.87830524e+01  2.10805665e+00]\n",
      " [ 1.16892960e-01 -1.29720864e+01 -1.44375829e+01 -3.52565521e+00\n",
      "  -2.69556925e+01  2.25564993e+01  9.81302164e-02  6.97888597e+00\n",
      "  -9.64263767e+00 -8.05517582e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_methods(lin_model, X_background=X_train[:100, :], X_instances=X_test[:5, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
