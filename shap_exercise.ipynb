{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courtesy of https://randomrealizations.com/posts/shap-from-scratch/\n",
    "\n",
    "import numpy as np \n",
    "from typing import Any, Callable, Iterable\n",
    "from itertools import chain, combinations\n",
    "\n",
    "class ShapFromScratchExplainer():\n",
    "    def __init__(self,\n",
    "                 model: Callable[[np.ndarray], float], \n",
    "                 background_dataset: np.ndarray,\n",
    "                 max_samples: int = None):\n",
    "        self.model = model # Set model\n",
    "        if max_samples: # If max samples, randomly sample a subset of the background dataset\n",
    "            max_samples = min(max_samples, background_dataset.shape[0]) \n",
    "            rng = np.random.default_rng()\n",
    "            self.background_dataset = rng.choice(background_dataset, \n",
    "                                                 size=max_samples, \n",
    "                                                 replace=False, axis=0)\n",
    "        else: # Use the full background dataset\n",
    "            self.background_dataset = background_dataset\n",
    "\n",
    "    def shap_values(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute SHAP values for instances in DataFrame or 2D array\"\"\"\n",
    "        shap_values = np.empty(X.shape)\n",
    "        # TODO: For each instance (i) and feature (j) in X, compute single SHAP value and put in shap_values[i, j]\n",
    "        return shap_values\n",
    "       \n",
    "    def _compute_single_shap_value(self, \n",
    "                                   feature: int,\n",
    "                                   instance: np.array) -> float:\n",
    "        \"\"\"\n",
    "        Compute a single SHAP value given feature of interest and instance\n",
    "        (equation 4 in SHAP paper)\n",
    "        \"\"\"\n",
    "        n_features = len(instance)\n",
    "        shap_value = 0\n",
    "        for subset in self._get_all_other_feature_subsets(n_features, feature):\n",
    "            n_subset = len(subset)\n",
    "            \n",
    "            prediction_with_feature = 0 # TODO: Make subset model prediction without the feature\n",
    "            prediction_without_feature = 0 # TODO: Make subset model prediction with the feature\n",
    "            \n",
    "            factor = 0 # TODO: Calculate permutation factor (equation 4 in SHAP paper, left side)\n",
    "            shap_value += 0 # TODO: Calculate SHAP value (equation 4 in SHAP paper, right side)\n",
    "        return shap_value\n",
    "    \n",
    "    def _get_all_subsets(self, items: list) -> Iterable:\n",
    "        \"\"\"Generate all possible subsets\"\"\"\n",
    "        return chain.from_iterable(combinations(items, r) for r in range(len(items)+1))\n",
    "    \n",
    "    def _get_all_other_feature_subsets(self, n_features, feature_of_interest):\n",
    "        \"\"\"Generate all subsets of features excluding the feature of interest\"\"\"\n",
    "        all_other_features = [j for j in range(n_features) if j != feature_of_interest]\n",
    "        return self._get_all_subsets(all_other_features)\n",
    "\n",
    "    def _permutation_factor(self, n_features, n_subset):\n",
    "        # TODO: Calculate a weighted average over all feature combinations (equation 4 in SHAP paper, left side)\n",
    "        return 0\n",
    "    \n",
    "    def _subset_model_approximation(self, \n",
    "                                    feature_subset: tuple[int, ...], \n",
    "                                    instance: np.array) -> float:\n",
    "        \"\"\" \n",
    "        Approximate subset model prediction (Equation 11 in SHAP paper)\n",
    "        \\hat{f}_S(x) = E_{x_{\\hat{S}}}[f_S(x)]\n",
    "        for feature subset S on single instance x\n",
    "        \"\"\"\n",
    "        masked_background_dataset = self.background_dataset.copy()\n",
    "        for j in range(masked_background_dataset.shape[1]):\n",
    "            if j in feature_subset:\n",
    "                masked_background_dataset[:, j] = instance[j]\n",
    "        conditional_expectation_of_model = np.mean(\n",
    "            self.model(masked_background_dataset)\n",
    "        )\n",
    "        return conditional_expectation_of_model          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# Load diabetes dataaset\n",
    "X, y = load_diabetes(as_frame=False, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Train some models\n",
    "lin_model = LinearRegression().fit(X_train, y_train)\n",
    "rfr_model = RandomForestRegressor().fit(X_train, y_train)\n",
    "gbt_model = GradientBoostingRegressor().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# (1) Compute SHAP values using ShapFromScratchExplainer and compute them using the SHAP library (KernelSHAP)\n",
    "# (2) Compare the two SHAP values (should be similar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
